{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gonzalezf/Tarea3-INF395/blob/master/Tarea3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "t6BYAAHUcCEZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
        "\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n",
        "\n",
        "<H3 align='center'> Tarea 3 - Aplicaciones de Redes Neuronales </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "**Temas**  \n",
        "* Modelos Generativos profundos: VAE (*Variational Autoencoder*) y GAN (*Generative Adversarial Network*).\n",
        "* Arquitectura encoder-decoder y mecanismo de antención.\n",
        "* Desafío en donde se aplique todo lo aprendido.\n",
        " \n",
        "\n",
        "** Formalidades **  \n",
        "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
        "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
        "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
        "* Fecha de entrega y discusión: -\n",
        "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea3-INF395-I-2018]\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "La tarea se divide en secciones:\n",
        "\n",
        "[1.](#primero) Modelos Generativos  \n",
        "[2.](#segundo) *Question-Answering*  \n",
        "[3.](#tercer) Challenge (*Object Counting*)\n",
        "\n",
        "*Nota: Para esta actividad, al igual que anteriores, si es que no se cuenta con GPU se recomienda utilizar el entorno virtual de __[Colaboratory - Google](https://colab.research.google.com/)__*"
      ]
    },
    {
      "metadata": {
        "id": "Et91H1QBMybY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Importar Librerías"
      ]
    },
    {
      "metadata": {
        "id": "N7sX4zulMz_A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input,Conv2D,Flatten,Dense,MaxPool2D\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import Reshape,Conv2DTranspose,Activation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lg4JuqCWcG3Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"primero\"></a>\n",
        "# 1. Modelos Generativos\n",
        "\n",
        "Las redes neuronales hoy en día han sido aplicados a muchos problemas, de los cuales algunos son necesarios tener un modelo generativo el cual pueda artificialmente sintetizar nuevos ejemplos que sean similares a los originales, éste tipo de aprendizaje se llama **Unsupervised Learning**. Existen diferentes *approaches* para ésto, de los cuales solo veremos 2.\n",
        "\n",
        "Vamos a trabajar con los datos anteriormente trabajados de MNIST.\n"
      ]
    },
    {
      "metadata": {
        "id": "zTcAxiVOcCh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a9ab5494-a8b3-40aa-da17-d5796c862838"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PnGg1URhcW3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = X_train.shape[1:]\n",
        "# color channels (1 = grayscale, 3 = RGB)\n",
        "channel = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "93RO6eAGegKU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## 1.1 *Variational Autoencoder* (VAE) [[1]](#refs)\n",
        "\n",
        "Los VAE son una variación a la arquitectura que ya vimos (autoencoder) en donde la codificación y decodificación están conectadas a través de un enfoque bayesiano en donde la codificación aprende los parámetros de alguna distribución de variables latentes de los datos y en donde el decodificador muestrea de ésta distribución de variables latentes para poder generar nuevos datos artificiales $\\hat{x}$. Dicho de otra palabras es un autoencoder que aprende el modelo de las variables latentes de los datos.\n",
        "\n",
        "\n",
        "El enfoque optimizador de los parámetros de la red neuronal $\\theta$ es que minimiza la reconstrucción de los datos (al igual que un autoencoder tradicional), en base a alguna medicicón de error (*mse* por ejemplo) agregando una regularización que se impone para que la distribución aprendida de las variables latentes sea de alguna distribución deseada *a priori*.  \n",
        "\n",
        "$$ Min \\ L(q_{\\theta}(x\\mid z),x) + KL( q_{\\theta}(z\\mid x) \\mid \\mid p_{\\theta}(z))$$\n",
        "\n",
        "Con $L$ la función de pérdida de reconstrucción, $KL$ la *KL Divergence* [[5]](#refs), $q_{\\hat{\\theta}}(x\\mid z)$ la recontrucción aleatoria de los datos a través de las variables latentes $z$ y  $p_{\\theta}(z)$ una distribución *a priori*. \n",
        "\n",
        "<img src=\"https://i.imgur.com/ZN6MyTx.png\" title=\"VAE\" width=\"60%\" />"
      ]
    },
    {
      "metadata": {
        "id": "irDBKyldf-Et",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> a) Defina la sección del *encoder* del VAE como el que se muestra en el código, de 3 bloque convolucionales y una bloque *fully conected*, con una distribución Normal multivariada de 2 componentes para las variables latentes. Describa la arquitectura utilizada para el *encoder*."
      ]
    },
    {
      "metadata": {
        "id": "j4ozV8NNeB4Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input image dimensions\n",
        "original_img_size = (img_rows, img_cols,channel)\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# convolution kernel size\n",
        "num_conv = 3\n",
        "latent_dim = 2\n",
        "intermediate_dim = 128\n",
        "\n",
        "## Encoder\n",
        "x = Input(shape=original_img_size)\n",
        "conv_1 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(x)\n",
        "conv_2 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(conv_1)\n",
        "conv_3 = Conv2D(filters*2, kernel_size=num_conv, padding='same', activation='relu', strides=2)(conv_2)\n",
        "flat = Flatten()(conv_3)\n",
        "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
        "z_mean = Dense(latent_dim,activation='linear')(hidden)\n",
        "z_log_var = Dense(latent_dim,activation='linear')(hidden)\n",
        "# build a model to project inputs on the latent space\n",
        "encoder = Model(x, z_mean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AJ0Vb1mvj-G3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">DESCRIBIR ARQUITECTURA </font>"
      ]
    },
    {
      "metadata": {
        "id": "T5L7sut7N9YZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero recordemos que los Autoencoders son redes neuronales que pueden ser usados para aprender eficientemente elementos de los datos de entrada. Dado algún conjunto de entrada, la red primero aplica una serie de transformaciones para 'map' *mapear* los datos en un espacio dimensional más pequeño (reduce las dimensiones de los datos). Esta parte es llamada *encoder*."
      ]
    },
    {
      "metadata": {
        "id": "unPPtWp5ODNp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Luego de esto, la red utiliza los datos codificados (encoded data) e intenta recrear el conjunto de datos original. Esta parte de la red se llama *decoder*. \n",
        "\n",
        "Lo anterior tiene mucha implicancias. Usando el *encoder*, podemos comprimir datos que sean \"entendedidos\"  por la red. Sin embargo, autoencoders son raramentes usadas para este propósito (se utilizan otros algoritmos para compresión de archivos jpg que son más eficientes),  A pesar de eso, autoencoders han sido muchas veces utilizados para desarrollar tareas donde deben eliminar ruido *noise* de imágenes. Encoders han recibido imágenes con ruido y han aprendido a cómo reconstruirlas."
      ]
    },
    {
      "metadata": {
        "id": "kmxROImFkL5_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "> b) Defina la sección del *decoder* del VAE como el que se muestra en el código, una tanda *fully conected* y con 3 bloque de la operación inversa a una convolución (**Convolución transpuesta** [[2]](#refs)), comente cómo ésta trabaja y los parámetros de stride como funcionan. Además se *setea* la distribución de las variables latentes como una distribución Normal multivariada de 2 componentes."
      ]
    },
    {
      "metadata": {
        "id": "Xte_JUJZj6Od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "6f52b725-d326-447a-f9e1-82f77b34f3bf"
      },
      "cell_type": "code",
      "source": [
        "## Decoder\n",
        "shape_before_flattening = K.int_shape(conv_3)[1:]\n",
        "# we instantiate these layers separately so as to reuse them later\n",
        "decoder_hid = Dense(intermediate_dim, activation='relu')\n",
        "decoder_upsample = Dense(np.prod(shape_before_flattening), activation='relu')\n",
        "decoder_reshape = Reshape(shape_before_flattening)\n",
        "decoder_deconv_1 = Conv2DTranspose(filters,kernel_size=num_conv, padding='same',strides=2,activation='relu')\n",
        "decoder_deconv_2 = Conv2DTranspose(filters,kernel_size=num_conv,padding='same', activation='relu')\n",
        "decoder_mean_squash = Conv2DTranspose(channel, kernel_size=num_conv,padding='same', activation='sigmoid')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-4d966fa413ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshape_before_flattening\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# we instantiate these layers separately so as to reuse them later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdecoder_hid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WQYu6uxckaVL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wfjXOAyyxjN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Question Answering"
      ]
    },
    {
      "metadata": {
        "id": "SgkiA9IUxneE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}